import akshare as ak
import pandas as pd
import numpy as np  # å…³é”®ä¿®å¤ç‚¹[3](@ref)
import os
import talib
from datetime import datetime
from dateutil.relativedelta import relativedelta
from tqdm import tqdm
import concurrent.futures
from functools import partial
import time
import urllib3
import random

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


def random_sleep(min_seconds=0.3, max_seconds=0.8):
    """éšæœºå»¶æ—¶å‡½æ•°"""
    sleep_time = random.uniform(min_seconds, max_seconds)
    time.sleep(sleep_time)


def process_price_code(code):
    """å¤„ç†ä»·æ ¼æ¥å£çš„è‚¡ç¥¨ä»£ç æ ¼å¼"""
    code_str = str(code).strip()
    num_part = ''.join(filter(str.isdigit, code_str))
    if not num_part:
        return None
    first_digit = num_part[0]
    if first_digit in ('6', '9'):
        return f'sh{num_part}'
    elif first_digit in ('0', '3', '2'):
        return f'sz{num_part}'
    else:
        return None


def get_date_range(years=5):
    """ç”ŸæˆåŠ¨æ€æ—¶é—´èŒƒå›´"""
    end_date = datetime.now().strftime("%Y%m%d")
    start_date = (datetime.now() - relativedelta(years=years)).strftime("%Y%m%d")
    return start_date, end_date


def pad_stock_code(code):
    """è¡¥å…¨è‚¡ç¥¨ä»£ç è‡³6ä½"""
    code_str = str(code).strip()
    return code_str.zfill(6)


def filter_by_date(df, start_date, end_date):
    """é€šç”¨æ—¥æœŸè¿‡æ»¤å‡½æ•°ï¼ˆå…¼å®¹ä¸åŒæ¥å£ï¼‰"""
    date_col = next((col for col in ['trade_date', 'date', 'æ—¥æœŸ'] if col in df.columns), None)
    if not date_col:
        raise ValueError(f"æœªæ‰¾åˆ°æ—¥æœŸå­—æ®µï¼Œå¯ç”¨åˆ—å: {df.columns.tolist()}")

    df['date'] = pd.to_datetime(df[date_col])
    start_dt = datetime.strptime(start_date, "%Y%m%d")
    end_dt = datetime.strptime(end_date, "%Y%m%d")
    return df[(df['date'] >= start_dt) & (df['date'] <= end_dt)]


def calculate_ta_indicators(df):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆKDJ+BBI+MACD+èµ„é‡‘æŒ‡æ ‡+PEé€šé“ï¼‰"""
    # KDJæŒ‡æ ‡
    df['K'], df['D'] = talib.STOCH(
        df['high'].values, df['low'].values, df['close'].values,
        fastk_period=9, slowk_period=3, slowk_matype=0,
        slowd_period=3, slowd_matype=0
    )
    df['J'] = 3 * df['K'] - 2 * df['D']

    # BBIæŒ‡æ ‡
    periods = [3, 6, 12, 24]
    for p in periods:
        df[f'MA{p}'] = talib.SMA(df['close'], timeperiod=p)
    df['BBI'] = df[[f'MA{p}' for p in periods]].mean(axis=1)
    df['BBI_DIF'] = df['BBI'].diff().fillna(0)

    # MACDæŒ‡æ ‡ï¼ˆå‚æ•°ä¸å›½å†…è½¯ä»¶å¯¹é½ï¼‰
    df['DIF'], df['DEA'], df['MACD'] = talib.MACD(
        df['close'],
        fastperiod=12,
        slowperiod=26,
        signalperiod=9
    )

    # è®¡ç®—çŸ­æœŸèµ„é‡‘æŒ‡æ ‡
    df['short_term_low'] = df['low'].rolling(window=3).min()
    df['short_term_high'] = df['close'].rolling(window=3).max()
    df['short_term_fund'] = 100 * (df['close'] - df['short_term_low']) / (df['short_term_high'] - df['short_term_low'])

    # è®¡ç®—é•¿æœŸèµ„é‡‘æŒ‡æ ‡
    df['long_term_low'] = df['low'].rolling(window=21).min()
    df['long_term_high'] = df['close'].rolling(window=21).max()
    df['long_term_fund'] = 100 * (df['close'] - df['long_term_low']) / (df['long_term_high'] - df['long_term_low'])

    # PEé€šé“è®¡ç®—
    if 'pe_ttm' in df.columns:
        # ç¡®ä¿pe_ttmåˆ—æ²¡æœ‰æ— æ•ˆå€¼
        df['pe_ttm'] = df['pe_ttm'].replace([np.inf, -np.inf], np.nan)
        df['pe_ttm'] = df['pe_ttm'].ffill().bfill()

        # æ–°PEé€šé“è®¡ç®—æ–¹æ³•
        min_pe = df['pe_ttm'].min()  # L2
        median_pe = df['pe_ttm'].median()  # M
        step = (median_pe - min_pe) / 2 if median_pe > min_pe else 0
        L2 = min_pe
        M = median_pe
        L1 = L2 + step
        H1 = M + step
        H2 = H1 + step

        # è®¡ç®—æŠ•èµ„æ”¶ç›Šç‡
        df['investment_income'] = df['close'] / df['pe_ttm'].replace(0, np.nan).fillna(1)

        # èµ‹å€¼PEé€šé“
        df['L2'] = L2
        df['L1'] = L1
        df['M'] = M
        df['H1'] = H1
        df['H2'] = H2

    # åˆ é™¤ä¸´æ—¶åˆ—
    df = df.drop(columns=[f'MA{p}' for p in periods] +
                         ['short_term_low', 'short_term_high', 'long_term_low', 'long_term_high'])

    return df


def merge_and_save(price_df, indicator_df, save_path, symbol):
    """é‡æ„ç‰ˆæ•°æ®åˆå¹¶ä¿å­˜å‡½æ•°ï¼ˆå«æŠ€æœ¯æŒ‡æ ‡ï¼‰"""
    try:
        # ========== é¢„å¤„ç†é˜¶æ®µ ==========
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        price_df = calculate_ta_indicators(price_df.copy())

        # æ·»åŠ è‚¡ç¥¨ä»£ç æ ‡è¯†
        price_df = price_df.assign(symbol=symbol)
        indicator_df = indicator_df.assign(symbol=symbol)

        # ========== æ—¥æœŸå¤„ç†ä¼˜åŒ– ==========
        price_df['date'] = pd.to_datetime(price_df['trade_date'] if 'trade_date' in price_df else price_df['date'])
        indicator_df['date'] = pd.to_datetime(indicator_df['trade_date'])

        # ========== åˆå¹¶é˜¶æ®µ ==========
        merged_df = pd.merge(
            price_df,
            indicator_df,
            on=['date', 'symbol'],
            how='inner',
            suffixes=('_price', '_indicator'),
            validate='one_to_one'
        ).sort_values('date').reset_index(drop=True)

        # æ–°å¢å»é‡æ“ä½œ
        merged_df = merged_df.drop_duplicates(subset=['date'], keep='last')

        # ========== æ•°æ®æ¸…æ´— ==========
        numeric_cols = merged_df.select_dtypes(include=np.number).columns.difference(['symbol']).tolist()
        numeric_cols = [col for col in numeric_cols if col not in ['date', 'symbol']]

        if numeric_cols:
            merged_df[numeric_cols] = merged_df.groupby('symbol', group_keys=False)[numeric_cols].apply(
                lambda x: x.ffill().bfill()
            )

        # ========== å­˜å‚¨é˜¶æ®µ ==========
        # åŸºç¡€åˆ—
        base_cols = ['date', 'symbol', 'open', 'high', 'low', 'close', 'volume', 'amount', 'outstanding_share',
                     'turnover']

        # æŠ€æœ¯æŒ‡æ ‡åˆ—
        ta_cols = ['K', 'D', 'J', 'BBI', 'BBI_DIF', 'DIF', 'DEA', 'MACD', 'short_term_fund', 'long_term_fund']

        # PEé€šé“åˆ—
        pe_cols = ['L2', 'L1', 'M', 'H1', 'H2', 'investment_income']

        # ä¼°å€¼æŒ‡æ ‡åˆ—
        value_cols = ['market_cap', 'float_market_cap', 'pe_ttm', 'pe_static', 'pb', 'peg', 'pcf', 'ps']

        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        all_columns = base_cols + ta_cols + pe_cols + value_cols
        output_columns = [col for col in all_columns if col in merged_df.columns]

        # éªŒè¯PEé€šé“åˆ—æ˜¯å¦å­˜åœ¨
        missing_pe_cols = [col for col in pe_cols if col not in output_columns]
        if missing_pe_cols:
            # é‡æ–°è®¡ç®—PEé€šé“ï¼Œé‡‡ç”¨ä¸calculate_ta_indicatorsä¸€è‡´çš„æ–°æ–¹æ³•
            merged_df['pe_ttm'] = merged_df['pe_ttm'].replace([np.inf, -np.inf, 0], np.nan).ffill().bfill()
            # è‹¥investment_incomeä¸å­˜åœ¨ï¼Œå…ˆè¡¥å……è®¡ç®—
            if 'investment_income' not in merged_df.columns:
                merged_df['investment_income'] = merged_df['close'] / merged_df['pe_ttm'].replace(0, np.nan).fillna(1)
            min_pe = merged_df['pe_ttm'].min()  # L2
            median_pe = merged_df['pe_ttm'].median()  # M
            step = (median_pe - min_pe) / 2 if median_pe > min_pe else 0
            L2 = min_pe
            M = median_pe
            L1 = L2 + step
            H1 = M + step
            H2 = H1 + step
            # èµ‹å€¼ä¸ºå¸¸æ•°ä¹˜ä»¥å¯¹åº”è¡Œçš„investment_income
            merged_df['L2'] = L2 * merged_df['investment_income']
            merged_df['L1'] = L1 * merged_df['investment_income']
            merged_df['M'] = M * merged_df['investment_income']
            merged_df['H1'] = H1 * merged_df['investment_income']
            merged_df['H2'] = H2 * merged_df['investment_income']
            # æ›´æ–°è¾“å‡ºåˆ—
            output_columns = [col for col in all_columns if col in merged_df.columns]

        # ä¿å­˜æ•°æ®
        merged_df[output_columns].to_csv(save_path, index=False, encoding='utf_8_sig')

    except Exception as e:
        print(f"âŒ {symbol} åˆå¹¶å¤±è´¥: {str(e)[:100]}...")
        raise


def process_single_stock(raw_code, price_code, start_date, end_date, save_dir):
    """å¤„ç†å•ä¸ªè‚¡ç¥¨çš„æ•°æ®è·å–å’Œä¿å­˜"""
    max_retries = 3
    retry_delay = 5  # é‡è¯•å»¶è¿Ÿç§’æ•°

    for attempt in range(max_retries):
        try:
            # è‚¡ç¥¨ä»£ç è½¬æ¢
            price_symbol = process_price_code(price_code)
            if not price_symbol:
                return f"âŒ æ— æ•ˆä»£ç : {price_code}"

            save_path = os.path.join(save_dir, f"{raw_code}.csv")

            # ================== æ–‡ä»¶å­˜åœ¨æ€§åˆ¤æ–­ ==================
            if os.path.exists(save_path):
                try:
                    # è¯»å–å†å²æ•°æ®
                    history_df = pd.read_csv(save_path, encoding='utf_8_sig')

                    # ç»Ÿä¸€åˆ—åå¤„ç†
                    history_df = history_df.rename(columns={
                        '\ufeffdate': 'date',
                        'trade_date': 'date',
                        'æ—¥æœŸ': 'date'
                    })

                    # ç¡®ä¿æ—¥æœŸåˆ—å­˜åœ¨å¹¶è½¬æ¢ä¸ºdatetime
                    if 'date' not in history_df.columns:
                        raise ValueError(f"æ—¥æœŸåˆ—ç¼ºå¤±ï¼Œå®é™…åˆ—å: {history_df.columns.tolist()}")

                    history_df['date'] = pd.to_datetime(history_df['date'])

                    # è·å–æœ€æ–°æ—¥æœŸ
                    latest_date = history_df['date'].max()
                    latest_date_str = latest_date.strftime("%Y%m%d")

                    # åˆ¤æ–­æ˜¯å¦å·²æ˜¯æœ€æ–°æ•°æ®
                    if latest_date_str == end_date:
                        return f"â© å·²æ˜¯æœ€æ–°æ•°æ®: {raw_code}"

                    # åˆ é™¤æ—©äºstart_dateçš„æ•°æ®
                    history_df = history_df[history_df['date'] >= pd.to_datetime(start_date)]

                    # è®¡ç®—å¢é‡èµ·å§‹æ—¥æœŸ
                    new_start = (latest_date + pd.Timedelta(days=1)).strftime("%Y%m%d")

                    # è·å–å¢é‡ä»·æ ¼æ•°æ®
                    temp_price_df = None
                    for _ in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
                        try:
                            random_sleep(1, 2)  # æ·»åŠ éšæœºå»¶æ—¶
                            temp_price_df = ak.stock_zh_a_daily(
                                symbol=price_symbol,
                                adjust="qfq",
                                start_date=new_start,
                                end_date=end_date
                            )
                            if temp_price_df is not None and not temp_price_df.empty:
                                break
                        except Exception as e:
                            print(f"è·å–ä»·æ ¼æ•°æ®å¤±è´¥ {raw_code}: {str(e)[:100]}")
                            random_sleep(2, 3)  # å¤±è´¥åå¢åŠ å»¶æ—¶

                    if temp_price_df is None or temp_price_df.empty:
                        return f"âš ï¸ æ— å¢é‡æ•°æ®: {raw_code}"

                    # ç»Ÿä¸€ä»·æ ¼æ•°æ®åˆ—å
                    temp_price_df = temp_price_df.rename(columns={'date': 'trade_date'})

                    # è·å–å¢é‡æŒ‡æ ‡æ•°æ®
                    temp_indicator_df = None
                    for _ in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
                        try:
                            random_sleep(2, 4)  # æŒ‡æ ‡æ•°æ®è·å–å¢åŠ æ›´é•¿çš„å»¶æ—¶
                            temp_indicator_df = ak.stock_value_em(symbol=raw_code)
                            if temp_indicator_df is not None and not temp_indicator_df.empty:
                                # é‡å‘½ååˆ—ä»¥åŒ¹é…ä¹‹å‰çš„æ ¼å¼
                                temp_indicator_df = temp_indicator_df.rename(columns={
                                    'æ•°æ®æ—¥æœŸ': 'trade_date',
                                    'æ€»å¸‚å€¼': 'market_cap',
                                    'æµé€šå¸‚å€¼': 'float_market_cap',
                                    'PE(TTM)': 'pe_ttm',
                                    'PE(é™)': 'pe_static',
                                    'å¸‚å‡€ç‡': 'pb',
                                    'PEGå€¼': 'peg',
                                    'å¸‚ç°ç‡': 'pcf',
                                    'å¸‚é”€ç‡': 'ps'
                                })
                                temp_indicator_df = filter_by_date(temp_indicator_df, new_start, end_date)
                                break
                        except Exception as e:
                            print(f"è·å–æŒ‡æ ‡æ•°æ®å¤±è´¥ {raw_code}: {str(e)[:100]}")
                            random_sleep(3, 5)  # å¤±è´¥åå¢åŠ æ›´é•¿çš„å»¶æ—¶

                    if temp_indicator_df is None or temp_indicator_df.empty:
                        return f"âš ï¸ æ— å¢é‡æŒ‡æ ‡: {raw_code}"

                    # åˆå¹¶å†å²æ•°æ®å’Œå¢é‡æ•°æ®
                    combined_price = pd.concat([
                        history_df,
                        temp_price_df
                    ], ignore_index=True)

                    # æ—¥æœŸå»é‡å’Œæ’åº
                    combined_price['date'] = pd.to_datetime(combined_price['date'])
                    combined_price = combined_price.drop_duplicates(subset=['date'], keep='last').sort_values('date')

                except Exception as e:
                    if attempt < max_retries - 1:
                        print(f"é‡è¯• {raw_code} - åŸå› : {str(e)[:100]}")
                        time.sleep(retry_delay)
                        continue
                    return f"âŒ å¤„ç†å†å²æ•°æ®å¤±è´¥: {str(e)[:100]}..."

            else:
                # ================== å…¨é‡æ•°æ®è·å– ==================
                try:
                    # è·å–å®Œæ•´ä»·æ ¼æ•°æ®
                    full_price_df = None
                    for _ in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
                        try:
                            random_sleep(0.3, 0.8)  # æ·»åŠ éšæœºå»¶æ—¶
                            full_price_df = ak.stock_zh_a_daily(
                                symbol=price_symbol,
                                adjust="qfq",
                                start_date=start_date,
                                end_date=end_date
                            )
                            if full_price_df is not None and not full_price_df.empty:
                                break
                        except Exception as e:
                            print(f"è·å–ä»·æ ¼æ•°æ®å¤±è´¥ {raw_code}: {str(e)[:100]}")
                            random_sleep(0.3, 0.8)  # å¤±è´¥åå¢åŠ å»¶æ—¶

                    if full_price_df is None or full_price_df.empty:
                        return f"âš ï¸ æ— ä»·æ ¼æ•°æ®: {raw_code}"

                    # ç»Ÿä¸€ä»·æ ¼æ•°æ®åˆ—å
                    full_price_df = full_price_df.rename(columns={'date': 'trade_date'})

                    # è·å–å®Œæ•´æŒ‡æ ‡æ•°æ®
                    full_indicator_df = None
                    for _ in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
                        try:
                            random_sleep(0.3, 0.8)  # æŒ‡æ ‡æ•°æ®è·å–å¢åŠ æ›´é•¿çš„å»¶æ—¶
                            full_indicator_df = ak.stock_value_em(symbol=raw_code)
                            if full_indicator_df is not None and not full_indicator_df.empty:
                                # é‡å‘½ååˆ—ä»¥åŒ¹é…ä¹‹å‰çš„æ ¼å¼
                                full_indicator_df = full_indicator_df.rename(columns={
                                    'æ•°æ®æ—¥æœŸ': 'trade_date',
                                    'æ€»å¸‚å€¼': 'market_cap',
                                    'æµé€šå¸‚å€¼': 'float_market_cap',
                                    'PE(TTM)': 'pe_ttm',
                                    'PE(é™)': 'pe_static',
                                    'å¸‚å‡€ç‡': 'pb',
                                    'PEGå€¼': 'peg',
                                    'å¸‚ç°ç‡': 'pcf',
                                    'å¸‚é”€ç‡': 'ps'
                                })
                                full_indicator_df = filter_by_date(full_indicator_df, start_date, end_date)
                                break
                        except Exception as e:
                            print(f"è·å–æŒ‡æ ‡æ•°æ®å¤±è´¥ {raw_code}: {str(e)[:100]}")
                            random_sleep(3, 5)  # å¤±è´¥åå¢åŠ æ›´é•¿çš„å»¶æ—¶

                    if full_indicator_df is None or full_indicator_df.empty:
                        return f"âš ï¸ æ— æŒ‡æ ‡æ•°æ®: {raw_code}"

                    combined_price = full_price_df

                except Exception as e:
                    if attempt < max_retries - 1:
                        print(f"é‡è¯• {raw_code} - åŸå› : {str(e)[:100]}")
                        time.sleep(retry_delay)
                        continue
                    return f"âŒ è·å–å…¨é‡æ•°æ®å¤±è´¥: {str(e)[:100]}..."

            # ================== ç»Ÿä¸€å­˜å‚¨å¤„ç† ==================
            try:
                # æœ€ç»ˆæ•°æ®åˆå¹¶ä¿å­˜
                merge_and_save(
                    price_df=combined_price,
                    indicator_df=temp_indicator_df if os.path.exists(save_path) else full_indicator_df,
                    save_path=save_path,
                    symbol=raw_code
                )
                return f"âœ… {raw_code}"
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"é‡è¯• {raw_code} - åŸå› : {str(e)[:100]}")
                    time.sleep(retry_delay)
                    continue
                return f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {str(e)[:100]}..."

        except Exception as e:
            if attempt < max_retries - 1:
                print(f"é‡è¯• {raw_code} - åŸå› : {str(e)[:100]}")
                time.sleep(retry_delay)
                continue
            return f"âŒ å¤„ç†å¤±è´¥: {str(e)[:100]}..."


def main():
    # è·¯å¾„é…ç½®
    excel_path = r"D:\Quant\01_SwProj\04_VectorBT\02_Lima\Lima_Gen1\01_RawData\02_ASharesPro\ASharesPro.xlsx"
    save_dir = r"D:\Quant\01_SwProj\04_VectorBT\02_Lima\Lima_Gen1\01_RawData\02_ASharesPro\StocksData"
    os.makedirs(save_dir, exist_ok=True)

    # è¯»å–Excelæ–‡ä»¶
    try:
        # è¯»å–Excelæ–‡ä»¶ï¼Œè·³è¿‡è¡¨å¤´
        df = pd.read_excel(excel_path, dtype={'è‚¡ç¥¨ä»£ç ': str})  # æ˜ç¡®æŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—ä¸ºå­—ç¬¦ä¸²ç±»å‹
        # å¤„ç†è‚¡ç¥¨ä»£ç 
        df.iloc[:, 0] = df.iloc[:, 0].apply(pad_stock_code)
        indicator_codes = df.iloc[:, 0].dropna().unique().tolist()
        # ä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºä»·æ ¼ä»£ç ï¼ˆå› ä¸ºç¬¬äºŒåˆ—ç°åœ¨æ˜¯è‚¡ç¥¨åç§°ï¼‰
        price_codes = df.iloc[:, 0].dropna().unique().tolist()
        total = len(indicator_codes)
    except Exception as e:
        print(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
        return

    # è·å–æ—¥æœŸèŒƒå›´
    start_date, end_date = get_date_range()

    # åˆ›å»ºè¿›åº¦æ¡
    with tqdm(total=total, desc="ğŸ”„ æ•°æ®åˆå¹¶è¿›åº¦") as pbar:
        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶è¡Œå¤„ç†ï¼Œå‡å°‘å¹¶å‘æ•°ä»¥é¿å…æœåŠ¡å™¨é™åˆ¶
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            # åˆ›å»ºåå‡½æ•°ï¼Œå›ºå®šéƒ¨åˆ†å‚æ•°
            process_func = partial(
                process_single_stock,
                start_date=start_date,
                end_date=end_date,
                save_dir=save_dir
            )

            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_stock = {
                executor.submit(process_func, raw_code, price_code): (raw_code, price_code)
                for raw_code, price_code in zip(indicator_codes, price_codes)
            }

            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in concurrent.futures.as_completed(future_to_stock):
                raw_code, price_code = future_to_stock[future]
                try:
                    result = future.result()
                    pbar.set_postfix_str(result)
                except Exception as e:
                    pbar.set_postfix_str(f"âŒ å¤±è´¥: {raw_code}")
                finally:
                    pbar.update(1)


if __name__ == "__main__":
    main()